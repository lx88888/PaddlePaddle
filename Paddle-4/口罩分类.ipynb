{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import json\n",
    "import paddle\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import paddle.fluid as fluid\n",
    "from multiprocessing import cpu_count\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "参数配置\n",
    "'''\n",
    "train_parameters = {\n",
    "    \"input_size\": [3, 224, 224],                              #输入图片的shape\n",
    "    \"class_dim\": -1,                                          #分类数\n",
    "    \"src_path\":\"/home/aistudio/work/maskDetect.zip\",#原始数据集路径\n",
    "    \"target_path\":\"/home/aistudio/data/\",                     #要解压的路径\n",
    "    \"train_list_path\": \"/home/aistudio/data/train.txt\",       #train.txt路径\n",
    "    \"eval_list_path\": \"/home/aistudio/data/eval.txt\",         #eval.txt路径\n",
    "    \"readme_path\": \"/home/aistudio/data/readme.json\",         #readme.json路径\n",
    "    \"label_dict\":{},                                          #标签字典\n",
    "    \"num_epochs\": 100,                                         #训练轮数\n",
    "    \"train_batch_size\": 15,                                    #训练时每个批次的大小\n",
    "    \"learning_strategy\": {                                    #优化函数相关的配置\n",
    "        \"lr\": 0.001                                           #超参数学习率\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_data(src_path,target_path):\n",
    "    '''\n",
    "    解压原始数据集，将src_path路径下的zip包解压至data目录下\n",
    "    '''\n",
    "    if(not os.path.isdir(target_path + \"maskDetect\")):     \n",
    "        z = zipfile.ZipFile(src_path, 'r')\n",
    "        z.extractall(path=target_path)\n",
    "        z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_list(target_path,train_list_path,eval_list_path):\n",
    "    '''\n",
    "    生成数据列表\n",
    "    '''\n",
    "    #存放所有类别的信息\n",
    "    class_detail = []\n",
    "    #获取所有类别保存的文件夹名称\n",
    "    data_list_path=target_path+\"maskDetect/\"\n",
    "    class_dirs = os.listdir(data_list_path)  \n",
    "    #总的图像数量\n",
    "    all_class_images = 0\n",
    "    #存放类别标签\n",
    "    class_label=0\n",
    "    #存放类别数目\n",
    "    class_dim = 0\n",
    "    #存储要写进eval.txt和train.txt中的内容\n",
    "    trainer_list=[]\n",
    "    eval_list=[]\n",
    "    #读取每个类别，['maskimages', 'nomaskimages']\n",
    "    for class_dir in class_dirs:\n",
    "        if class_dir != \".DS_Store\":\n",
    "            class_dim += 1\n",
    "            #每个类别的信息\n",
    "            class_detail_list = {}\n",
    "            eval_sum = 0\n",
    "            trainer_sum = 0\n",
    "            #统计每个类别有多少张图片\n",
    "            class_sum = 0\n",
    "            #获取类别路径 \n",
    "            path = data_list_path  + class_dir\n",
    "            # 获取所有图片\n",
    "            img_paths = os.listdir(path)\n",
    "            for img_path in img_paths:                                  # 遍历文件夹下的每个图片\n",
    "                name_path = path + '/' + img_path                       # 每张图片的路径\n",
    "                if class_sum % 10 == 0:                                 # 每10张图片取一个做验证数据\n",
    "                    eval_sum += 1                                       # test_sum为测试数据的数目\n",
    "                    eval_list.append(name_path + \"\\t%d\" % class_label + \"\\n\")\n",
    "                else:\n",
    "                    trainer_sum += 1 \n",
    "                    trainer_list.append(name_path + \"\\t%d\" % class_label + \"\\n\")#trainer_sum测试数据的数目\n",
    "                class_sum += 1                                          #每类图片的数目\n",
    "                all_class_images += 1                                   #所有类图片的数目\n",
    "             \n",
    "            # 说明的json文件的class_detail数据\n",
    "            class_detail_list['class_name'] = class_dir             #类别名称，如jiangwen\n",
    "            class_detail_list['class_label'] = class_label          #类别标签\n",
    "            class_detail_list['class_eval_images'] = eval_sum       #该类数据的测试集数目\n",
    "            class_detail_list['class_trainer_images'] = trainer_sum #该类数据的训练集数目\n",
    "            class_detail.append(class_detail_list)  \n",
    "            #初始化标签列表\n",
    "            train_parameters['label_dict'][str(class_label)] = class_dir\n",
    "            class_label += 1 \n",
    "            \n",
    "    #初始化分类数\n",
    "    train_parameters['class_dim'] = class_dim\n",
    "\n",
    "   \n",
    "    \n",
    "    #乱序  \n",
    "    random.shuffle(eval_list)\n",
    "    with open(eval_list_path, 'a') as f:\n",
    "        for eval_image in eval_list:\n",
    "            f.write(eval_image) \n",
    "            \n",
    "    random.shuffle(trainer_list)\n",
    "    with open(train_list_path, 'a') as f2:\n",
    "        for train_image in trainer_list:\n",
    "            f2.write(train_image) \n",
    "\n",
    "    # 说明的json文件信息\n",
    "    readjson = {}\n",
    "    readjson['all_class_name'] = data_list_path                  #文件父目录\n",
    "    readjson['all_class_images'] = all_class_images\n",
    "    readjson['class_detail'] = class_detail\n",
    "    jsons = json.dumps(readjson, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "    with open(train_parameters['readme_path'],'w') as f:\n",
    "        f.write(jsons)\n",
    "    print ('生成数据列表完成！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_reader(file_list):\n",
    "    '''\n",
    "    自定义reader\n",
    "    '''\n",
    "    def reader():\n",
    "        with open(file_list, 'r') as f:\n",
    "            lines = [line.strip() for line in f]\n",
    "            for line in lines:\n",
    "                img_path, lab = line.strip().split('\\t')\n",
    "                img = Image.open(img_path) \n",
    "                if img.mode != 'RGB': \n",
    "                    img = img.convert('RGB') \n",
    "                img = img.resize((224, 224), Image.BILINEAR)\n",
    "                img = np.array(img).astype('float32') \n",
    "                img = img.transpose((2, 0, 1))  # HWC to CHW \n",
    "                img = img/255                # 像素值归一化 \n",
    "                yield img, int(lab) \n",
    "    return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "参数初始化\n",
    "'''\n",
    "src_path=train_parameters['src_path']\n",
    "target_path=train_parameters['target_path']\n",
    "train_list_path=train_parameters['train_list_path']\n",
    "eval_list_path=train_parameters['eval_list_path']\n",
    "batch_size=train_parameters['train_batch_size']\n",
    "\n",
    "'''\n",
    "解压原始数据到指定路径\n",
    "'''\n",
    "unzip_data(src_path,target_path)\n",
    "\n",
    "'''\n",
    "划分训练集与验证集，乱序，生成数据列表\n",
    "'''\n",
    "#每次生成数据列表前，首先清空train.txt和eval.txt\n",
    "with open(train_list_path, 'w') as f: \n",
    "    f.seek(0)\n",
    "    f.truncate() \n",
    "with open(eval_list_path, 'w') as f: \n",
    "    f.seek(0)\n",
    "    f.truncate() \n",
    "#生成数据列表   \n",
    "get_data_list(target_path,train_list_path,eval_list_path)\n",
    "\n",
    "'''\n",
    "构造数据提供器\n",
    "'''\n",
    "train_reader = paddle.batch(custom_reader(train_list_path),\n",
    "                            batch_size=batch_size,\n",
    "                            drop_last=True)\n",
    "eval_reader = paddle.batch(custom_reader(eval_list_path),\n",
    "                            batch_size=batch_size,\n",
    "                            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPool(fluid.dygraph.Layer):\n",
    "    '''卷积+池化'''\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 num_filters,\n",
    "                 filter_size,\n",
    "                 pool_size,\n",
    "                 pool_stride,\n",
    "                 groups,\n",
    "                 pool_padding=0,\n",
    "                 pool_type='max',\n",
    "                 conv_stride=1,\n",
    "                 conv_padding=1,\n",
    "                 act=None):\n",
    "        super(ConvPool, self).__init__()  \n",
    "\n",
    "        self._conv2d_list = []\n",
    "\n",
    "        for i in range(groups):\n",
    "            conv2d = self.add_sublayer(   #返回一个由所有子层组成的列表。\n",
    "                'bb_%d' % i,\n",
    "                fluid.dygraph.Conv2D(\n",
    "                num_channels=num_channels, #通道数\n",
    "                num_filters=num_filters,   #卷积核个数\n",
    "                filter_size=filter_size,   #卷积核大小\n",
    "                stride=conv_stride,        #步长\n",
    "                padding=conv_padding,      #padding大小，默认为0\n",
    "                act=act)\n",
    "            )\n",
    "        self._conv2d_list.append(conv2d)   \n",
    "\n",
    "        self._pool2d = fluid.dygraph.Pool2D(\n",
    "            pool_size=pool_size,           #池化核大小\n",
    "            pool_type=pool_type,           #池化类型，默认是最大池化\n",
    "            pool_stride=pool_stride,       #池化步长\n",
    "            pool_padding=pool_padding      #填充大小\n",
    "            )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        for conv in self._conv2d_list:\n",
    "            x = conv(x)\n",
    "        x = self._pool2d(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "＃ＶＧＧ网络定义\n",
    "class VGGNet(fluid.dygraph.Layer):             # VGG网络\n",
    "    def __init__(self):\n",
    "        super(VGGNet, self).__init__()\n",
    "\n",
    "        self.convpool01 = ConvPool(3,64,3,2,2,2,act=\"relu\") #3:通道数 64:卷积核个数 3:卷积核大小 2:池化核大小 2:池化步长 2:连续卷积个数\n",
    "        self.convpool02 = ConvPool(64,128,3,2,2,2,act=\"relu\")\n",
    "        self.convpool03 = ConvPool(128,256,3,2,2,3,act=\"relu\")\n",
    "        self.convpool04 = ConvPool(256,512,3,2,2,3,act=\"relu\")\n",
    "        self.convpool05 = ConvPool(512,512,3,2,2,3,act=\"relu\")\n",
    "\n",
    "        self.pool_5_shape = 512*7*7\n",
    "        self.fc01 = fluid.dygraph.Linear(self.pool_5_shape,4096,act=\"relu\")\n",
    "        self.fc02 = fluid.dygraph.Linear(4096,4096,act=\"relu\")\n",
    "        self.fc03 = fluid.dygraph.Linear(4096,2,act=\"softmax\")\n",
    "\n",
    "    def forward(self, inputs, label=None):\n",
    "        # print(inputs.shape)   \n",
    "        \"\"\"前向计算\"\"\"\n",
    "        out = self.convpool01(inputs)\n",
    "        out = self.convpool02(out)\n",
    "        out = self.convpool03(out)\n",
    "        out = self.convpool04(out)\n",
    "        out = self.convpool05(out)\n",
    "\n",
    "        out = fluid.layers.reshape(out, shape=[-1, 512*7*7])\n",
    "        out = self.fc01(out)\n",
    "        out = self.fc02(out)\n",
    "        out = self.fc03(out)\n",
    "\n",
    "        if label is not None:\n",
    "            acc = fluid.layers.accuracy(input=out, label=label)\n",
    "            return out, acc\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_iter=0\n",
    "all_train_iters=[]\n",
    "all_train_costs=[]\n",
    "all_train_accs=[]\n",
    "\n",
    "def draw_train_process(title,iters,costs,accs,label_cost,lable_acc):\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"iter\", fontsize=20)\n",
    "    plt.ylabel(\"cost/acc\", fontsize=20)\n",
    "    plt.plot(iters, costs,color='red',label=label_cost) \n",
    "    plt.plot(iters, accs,color='green',label=lable_acc) \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_process(title,color,iters,data,label):\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"iter\", fontsize=20)\n",
    "    plt.ylabel(label, fontsize=20)\n",
    "    plt.plot(iters, data,color=color,label=label) \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "模型训练\n",
    "'''\n",
    "#with fluid.dygraph.guard(place = fluid.CUDAPlace(0)):\n",
    "with fluid.dygraph.guard():\n",
    "    print(train_parameters['class_dim'])\n",
    "    print(train_parameters['label_dict'])\n",
    "    vgg = VGGNet()\n",
    "    optimizer=fluid.optimizer.SGDOptimizer(learning_rate=train_parameters['learning_strategy']['lr'],parameter_list=vgg.parameters()) \n",
    "    for epoch_num in range(train_parameters['num_epochs']):\n",
    "        for batch_id, data in enumerate(train_reader()):\n",
    "            dy_x_data = np.array([x[0] for x in data]).astype('float32')           \n",
    "            y_data = np.array([x[1] for x in data]).astype('int64')      \n",
    "            y_data = y_data[:, np.newaxis]\n",
    "\n",
    "            #将Numpy转换为DyGraph接收的输入\n",
    "            img = fluid.dygraph.to_variable(dy_x_data)\n",
    "            label = fluid.dygraph.to_variable(y_data)\n",
    "\n",
    "            out,acc = vgg(img,label)\n",
    "            loss = fluid.layers.cross_entropy(out, label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "\n",
    "            #使用backward()方法可以执行反向网络\n",
    "            avg_loss.backward()\n",
    "            optimizer.minimize(avg_loss)\n",
    "             \n",
    "            #将参数梯度清零以保证下一轮训练的正确性\n",
    "            vgg.clear_gradients()\n",
    "            \n",
    "\n",
    "            all_train_iter=all_train_iter+train_parameters['train_batch_size']\n",
    "            all_train_iters.append(all_train_iter)\n",
    "            all_train_costs.append(loss.numpy()[0])\n",
    "            all_train_accs.append(acc.numpy()[0])\n",
    "                \n",
    "            if batch_id % 1 == 0:\n",
    "                print(\"Loss at epoch {} step {}: {}, acc: {}\".format(epoch_num, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "\n",
    "    draw_train_process(\"training\",all_train_iters,all_train_costs,all_train_accs,\"trainning cost\",\"trainning acc\")  \n",
    "    draw_process(\"trainning loss\",\"red\",all_train_iters,all_train_costs,\"trainning loss\")\n",
    "    draw_process(\"trainning acc\",\"green\",all_train_iters,all_train_accs,\"trainning acc\")  \n",
    "    \n",
    "    #保存模型参数\n",
    "    fluid.save_dygraph(vgg.state_dict(), \"vgg\")   \n",
    "    print(\"Final loss: {}\".format(avg_loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "模型校验\n",
    "'''\n",
    "with fluid.dygraph.guard():\n",
    "    model, _ = fluid.load_dygraph(\"vgg\")\n",
    "    vgg = VGGNet()\n",
    "    vgg.load_dict(model)\n",
    "    vgg.eval()\n",
    "    accs = []\n",
    "    for batch_id, data in enumerate(eval_reader()):\n",
    "        dy_x_data = np.array([x[0] for x in data]).astype('float32')\n",
    "        y_data = np.array([x[1] for x in data]).astype('int')\n",
    "        y_data = y_data[:, np.newaxis]\n",
    "        \n",
    "        img = fluid.dygraph.to_variable(dy_x_data)\n",
    "        label = fluid.dygraph.to_variable(y_data)\n",
    "\n",
    "        out, acc = vgg(img, label)\n",
    "        lab = np.argsort(out.numpy())\n",
    "        accs.append(acc.numpy()[0])\n",
    "print(np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    '''\n",
    "    预测图片预处理\n",
    "    '''\n",
    "    img = Image.open(img_path) \n",
    "    if img.mode != 'RGB': \n",
    "        img = img.convert('RGB') \n",
    "    img = img.resize((224, 224), Image.BILINEAR)\n",
    "    img = np.array(img).astype('float32') \n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW \n",
    "    img = img/255                # 像素值归一化 \n",
    "    return img\n",
    "\n",
    "label_dic = train_parameters['label_dict']\n",
    "\n",
    "'''\n",
    "模型预测\n",
    "'''\n",
    "with fluid.dygraph.guard():\n",
    "    model, _ = fluid.dygraph.load_dygraph(\"vgg\")\n",
    "    vgg = VGGNet()\n",
    "    vgg.load_dict(model)\n",
    "    vgg.eval()\n",
    "    \n",
    "    #展示预测图片\n",
    "    infer_path='/home/aistudio/work/3.jpg'\n",
    "    img = Image.open(infer_path)\n",
    "    plt.imshow(img)          #根据数组绘制图像\n",
    "    plt.show()               #显示图像\n",
    "\n",
    "    #对预测图片进行预处理\n",
    "    infer_imgs = []\n",
    "    infer_imgs.append(load_image(infer_path))\n",
    "    infer_imgs = np.array(infer_imgs)\n",
    "   \n",
    "    for  i in range(len(infer_imgs)):\n",
    "        data = infer_imgs[i]\n",
    "        dy_x_data = np.array(data).astype('float32')\n",
    "        dy_x_data=dy_x_data[np.newaxis,:, : ,:]\n",
    "        img = fluid.dygraph.to_variable(dy_x_data)\n",
    "        out = vgg(img)\n",
    "        lab = np.argmax(out.numpy())  #argmax():返回最大数的索引\n",
    "        print(\"第{}个样本,被预测为：{}\".format(i+1,label_dic[str(lab)]))\n",
    "        \n",
    "print(\"结束\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}