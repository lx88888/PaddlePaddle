{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "＃　一、数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#解压数据\n",
    "!unzip -q -o data/data1917/train_new.zip\n",
    "!unzip -q -o data/data1917/test_new.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载相关类库\n",
    "import zipfile\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter \n",
    "import scipy\n",
    "from matplotlib import cm as CM\n",
    "from paddle.utils.plot import Ploter\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "查看train.json相关信息，重点关注annotations中的标注信息\n",
    "'''\n",
    "f = open('/home/aistudio/data/data1917/train.json',encoding='utf-8')\n",
    "content = json.load(f)\n",
    "\n",
    "'''\n",
    "将上面的到的content中的name中的“stage1/”去掉\n",
    "'''\n",
    "for j in range(len(content['annotations'])):\n",
    "    content['annotations'][j]['name'] = content['annotations'][j]['name'].lstrip('stage1').lstrip('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "使用高斯滤波变换生成密度图\n",
    "'''\n",
    "def gaussian_filter_density(gt):\n",
    "   \n",
    "    # 初始化密度图\n",
    "    density = np.zeros(gt.shape, dtype=np.float32)\n",
    "    \n",
    "    # 获取gt中不为0的元素的个数\n",
    "    gt_count = np.count_nonzero(gt)\n",
    "    \n",
    "    # 如果gt全为0，就返回全0的密度图\n",
    "    if gt_count == 0:\n",
    "        return density\n",
    "    \n",
    "    pts = np.array(list(zip(np.nonzero(gt)[1].ravel(), np.nonzero(gt)[0].ravel())))\n",
    "    \n",
    "\n",
    "    for i, pt in enumerate(pts):\n",
    "        pt2d = np.zeros(gt.shape, dtype=np.float32)\n",
    "        pt2d[pt[1],pt[0]] = 1.\n",
    "        if gt_count > 1:\n",
    "            # sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1\n",
    "            sigma = 25\n",
    "        else:\n",
    "            sigma = np.average(np.array(gt.shape))/2./2. \n",
    "        \n",
    "        density += scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode='constant')\n",
    "\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "图片操作：对图片进行resize、归一化，将方框标注变为点标注\n",
    "返回：resize后的图片 和 gt\n",
    "'''\n",
    "def picture_opt(img,ann):\n",
    "    size_x,size_y = img.size\n",
    "    train_img_size = (640,480)\n",
    "    img = img.resize(train_img_size,Image.ANTIALIAS)\n",
    "    img = np.array(img)                  \n",
    "    img = img / 255.0\n",
    "\n",
    "    gt = []\n",
    "    for b_l in range(len(ann)):\n",
    "        # 假设人体是使用方框标注的，通过求均值的方法将框变为点\n",
    "        if 'w' in ann[b_l].keys(): \n",
    "            x = (ann[b_l]['x']+(ann[b_l]['x']+ann[b_l]['w']))/2\n",
    "            y = ann[b_l]['y']+20\n",
    "            x = (x*640/size_x)/8\n",
    "            y = (y*480/size_y)/8\n",
    "            gt.append((x,y))   \n",
    "        else:\n",
    "            x = ann[b_l]['x']\n",
    "            y = ann[b_l]['y']\n",
    "            x = (x*640/size_x)/8\n",
    "            y = (y*480/size_y)/8\n",
    "            gt.append((x,y)) \n",
    "   \n",
    "    return img,gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "密度图处理\n",
    "'''\n",
    "def ground(img,gt):\n",
    "    imgs = img\n",
    "    x = imgs.shape[0]/8\n",
    "    y = imgs.shape[1]/8\n",
    "    k = np.zeros((int(x),int(y)))\n",
    "\n",
    "    for i in range(0,len(gt)):\n",
    "        if int(gt[i][1]) < int(x) and int(gt[i][0]) < int(y):\n",
    "            k[int(gt[i][1]),int(gt[i][0])]=1\n",
    "\n",
    "    k = gaussian_filter_density(k)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "定义数据生成器\n",
    "'''\n",
    "def train_set():\n",
    "    def inner():\n",
    "        for ig_index in range(2000):                                                 #遍历所有图片\n",
    "            if len(content['annotations'][ig_index]['annotation']) == 2:continue\n",
    "            if len(content['annotations'][ig_index]['annotation']) == 3:continue\n",
    "            if content['annotations'][ig_index]['ignore_region']:                      #把忽略区域都用像素为0填上\n",
    "                ig_list = []                                                           #存放忽略区1的数据\n",
    "                ig_list1 = []                                                          #存放忽略区2的数据\n",
    "                # print(content['annotations'][ig_index]['ignore_region'])\n",
    "                if len(content['annotations'][ig_index]['ignore_region'])==1:           #因为每张图的忽略区域最多2个，这里是为1的情况\n",
    "                    # print('ig1',ig_index)\n",
    "                    ign_rge = content['annotations'][ig_index]['ignore_region'][0]       #取第一个忽略区的数据\n",
    "                    for ig_len in range(len(ign_rge)):                                   #遍历忽略区坐标个数，组成多少变型\n",
    "                        ig_list.append([ign_rge[ig_len]['x'],ign_rge[ig_len]['y']])       #取出每个坐标的x,y然后组成一个小列表放到ig_list\n",
    "                    ig_cv_img = cv2.imread(content['annotations'][ig_index]['name'])      #用cv2读取一张图片\n",
    "                    pts = np.array(ig_list,np.int32)                                      #把ig_list转成numpy.ndarray数据格式，为了填充需要\n",
    "                    cv2.fillPoly(ig_cv_img,[pts],(0,0,0),cv2.LINE_AA)                     #使用cv2.fillPoly方法对有忽略区的图片用像素为0填充\n",
    "                \n",
    "                    ig_img = Image.fromarray(cv2.cvtColor(ig_cv_img,cv2.COLOR_BGR2RGB))   #cv2转PIL\n",
    "                    \n",
    "                    ann = content['annotations'][ig_index]['annotation']          #把所有标注的信息读取出来\n",
    "                                                                  \n",
    "                    ig_im,gt = picture_opt(ig_img,ann)\n",
    "                    k = ground(ig_im,gt)\n",
    "                   \n",
    "                    groundtruth = np.asarray(k)\n",
    "                    groundtruth = groundtruth.T.astype('float32')\n",
    "                    ig_im = ig_im.transpose().astype('float32')\n",
    "                    yield ig_im,groundtruth\n",
    "                    \n",
    "                if len(content['annotations'][ig_index]['ignore_region'])==2:           #有2个忽略区域\n",
    "                    # print('ig2',ig_index)\n",
    "                    ign_rge = content['annotations'][ig_index]['ignore_region'][0]\n",
    "                    ign_rge1 = content['annotations'][ig_index]['ignore_region'][1]\n",
    "                    for ig_len in range(len(ign_rge)):\n",
    "                        ig_list.append([ign_rge[ig_len]['x'],ign_rge[ig_len]['y']])\n",
    "                    for ig_len1 in range(len(ign_rge1)):\n",
    "                        ig_list1.append([ign_rge1[ig_len1]['x'],ign_rge1[ig_len1]['y']])  \n",
    "                    ig_cv_img2 = cv2.imread(content['annotations'][ig_index]['name'])\n",
    "                    pts = np.array(ig_list,np.int32)\n",
    "                    pts1 = np.array(ig_list1,np.int32)\n",
    "                    cv2.fillPoly(ig_cv_img2,[pts],(0,0,0),cv2.LINE_AA)                \n",
    "                    cv2.fillPoly(ig_cv_img2,[pts1],(0,0,0),cv2.LINE_AA)\n",
    "                    \n",
    "                    ig_img2 = Image.fromarray(cv2.cvtColor(ig_cv_img2,cv2.COLOR_BGR2RGB))   #cv2转PIL\n",
    "                    \n",
    "                    ann = content['annotations'][ig_index]['annotation']                    #把所有标注的信息读取出来\n",
    "                                                                  \n",
    "                    ig_im,gt = picture_opt(ig_img2,ann)\n",
    "                    k = ground(ig_im,gt)\n",
    "                    k = np.zeros((int(ig_im.shape[0]/8),int(ig_im.shape[1]/8)))\n",
    "                    \n",
    "                    groundtruth = np.asarray(k)\n",
    "                    groundtruth = groundtruth.T.astype('float32')\n",
    "                    ig_im = ig_im.transpose().astype('float32')\n",
    "                    yield ig_im,groundtruth\n",
    "                    \n",
    "            else:\n",
    "                img = Image.open(content['annotations'][ig_index]['name'])\n",
    "                ann = content['annotations'][ig_index]['annotation']          #把所有标注的信息读取出来\n",
    "                \n",
    "                im,gt = picture_opt(img,ann)\n",
    "                k = ground(im,gt)\n",
    "                \n",
    "                groundtruth = np.asarray(k)\n",
    "                groundtruth = groundtruth.T.astype('float32')\n",
    "                im = im.transpose().astype('float32')\n",
    "                yield im,groundtruth\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=30    #每次取30张\n",
    "# 设置训练reader\n",
    "train_reader = paddle.batch(\n",
    "    paddle.reader.shuffle(\n",
    "        train_set(), buf_size=512),\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(fluid.dygraph.Layer):\n",
    "    '''\n",
    "    网络\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        \n",
    "        self.conv01_1 = fluid.dygraph.Conv2D(num_channels=3, num_filters=64,filter_size=3,padding=1,act=\"relu\")\n",
    "        self.pool01=fluid.dygraph.Pool2D(pool_size=2,pool_type='max',pool_stride=2)\n",
    "\n",
    "        self.conv02_1 = fluid.dygraph.Conv2D(num_channels=64, num_filters=128,filter_size=3, padding=1,act=\"relu\")\n",
    "        self.pool02=fluid.dygraph.Pool2D(pool_size=2,pool_type='max',pool_stride=2)\n",
    "\n",
    "        self.conv03_1 = fluid.dygraph.Conv2D(num_channels=128, num_filters=256,filter_size=3, padding=1,act=\"relu\")\n",
    "        self.pool03=fluid.dygraph.Pool2D(pool_size=2,pool_type='max',pool_stride=2)\n",
    "\n",
    "        self.conv04_1 = fluid.dygraph.Conv2D(num_channels=256, num_filters=512,filter_size=3, padding=1,act=\"relu\")\n",
    "\n",
    "        self.conv05_1 = fluid.dygraph.Conv2D(num_channels=512, num_filters=512,filter_size=3,padding=1, act=\"relu\")\n",
    "      \n",
    "\n",
    "        self.conv06 = fluid.dygraph.Conv2D(num_channels=512,num_filters=256,filter_size=3,padding=1,act='relu')\n",
    "        self.conv07 = fluid.dygraph.Conv2D(num_channels=256,num_filters=128,filter_size=3,padding=1,act='relu')\n",
    "        self.conv08 = fluid.dygraph.Conv2D(num_channels=128,num_filters=64,filter_size=3,padding=1,act='relu')\n",
    "        self.conv09 = fluid.dygraph.Conv2D(num_channels=64,num_filters=1,filter_size=1,padding=0,act=None)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs, label=None):\n",
    "        \"\"\"前向计算\"\"\"\n",
    "        out = self.conv01_1(inputs)\n",
    "        \n",
    "        out = self.pool01(out)\n",
    "\n",
    "        out = self.conv02_1(out)\n",
    "       \n",
    "        out = self.pool02(out)\n",
    "\n",
    "        out = self.conv03_1(out)\n",
    "        \n",
    "        out = self.pool03(out)\n",
    "\n",
    "        out = self.conv04_1(out)    \n",
    "\n",
    "        out = self.conv05_1(out)\n",
    "        out = self.conv06(out)\n",
    "        out = self.conv07(out)\n",
    "        out = self.conv08(out)\n",
    "        out = self.conv09(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "模型训练\n",
    "'''\n",
    "with fluid.dygraph.guard(place = fluid.CUDAPlace(0)):\n",
    "    cnn = CNN()\n",
    "    optimizer=fluid.optimizer.AdamOptimizer(learning_rate=0.001,parameter_list=cnn.parameters()) \n",
    "    for epoch_num in range(5):\n",
    "        for batch_id, data in enumerate(train_reader()):\n",
    "            dy_x_data = np.array([x[0] for x in data]).astype('float32')           \n",
    "            y_data = np.array([x[1] for x in data]).astype('float32') \n",
    "            y_data = y_data[:,np.newaxis] \n",
    "           \n",
    "            #将Numpy转换为DyGraph接收的输入\n",
    "            img = fluid.dygraph.to_variable(dy_x_data)\n",
    "            label = fluid.dygraph.to_variable(y_data)\n",
    "            label.stop_gradient = True\n",
    "\n",
    "            out = cnn(img,label)\n",
    "            loss = fluid.layers.square_error_cost(out, label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "\n",
    "            #使用backward()方法可以执行反向网络\n",
    "            avg_loss.backward()\n",
    "            optimizer.minimize(avg_loss)\n",
    "             \n",
    "            #将参数梯度清零以保证下一轮训练的正确性\n",
    "            cnn.clear_gradients()\n",
    "            \n",
    "            dy_param_value = {}\n",
    "            for param in cnn.parameters():\n",
    "                dy_param_value[param.name] = param.numpy\n",
    "                \n",
    "            if batch_id % 20 == 0:\n",
    "                print(\"Loss at epoch {} step {}: {}\".format(epoch_num, batch_id, avg_loss.numpy()))\n",
    "    #保存模型参数\n",
    "    fluid.save_dygraph(cnn.state_dict(), \"cnn\")   \n",
    "    print(\"Final loss: {}\".format(avg_loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "\n",
    "'''\n",
    "模型预测\n",
    "'''\n",
    "with fluid.dygraph.guard():\n",
    "    model, _ = fluid.dygraph.load_dygraph(\"cnn\")\n",
    "    cnn = CNN()\n",
    "    cnn.load_dict(model)\n",
    "    cnn.eval()\n",
    "\n",
    "    #获取预测图片列表\n",
    "    test_zfile = zipfile.ZipFile(\"/home/aistudio/data/data1917/test_new.zip\")\n",
    "    l_test = []\n",
    "    for test_fname in test_zfile.namelist()[1:]:\n",
    "        \n",
    "        l_test.append(test_fname)\n",
    "   \n",
    "\n",
    "    for  index in range(len(l_test)):\n",
    "       \n",
    "        test_img = Image.open(l_test[index])\n",
    "        test_img = test_img.resize((640,480))\n",
    "        test_im = np.array(test_img)\n",
    "        test_im = test_im / 255.0\n",
    "        test_im = test_im.transpose().reshape(3,640,480).astype('float32')\n",
    "        l_test[index] = l_test[index].lstrip('test').lstrip('/')\n",
    "\n",
    "        dy_x_data = np.array(test_im).astype('float32')\n",
    "        dy_x_data=dy_x_data[np.newaxis,:, : ,:]\n",
    "        img = fluid.dygraph.to_variable(dy_x_data)\n",
    "        out = cnn(img)\n",
    "        temp=out[0][0]\n",
    "        temp=temp.numpy()\n",
    "        people =np.sum(temp)\n",
    "        data_dict[l_test[index]]=int(people)\n",
    "        \n",
    "import csv\n",
    "\n",
    "with open('results.csv', 'w') as csvfile:\n",
    "\n",
    "    fieldnames = ['id', 'predicted']\n",
    "\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    for k,v in data_dict.items():\n",
    "\n",
    "        writer.writerow({'id': k, 'predicted':v})\n",
    "print(\"结束\")"
   ]
  }
 ]
}