{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "'ls' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n���������ļ���\n"
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "'ls' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n���������ļ���\n"
    }
   ],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "'rm' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n���������ļ���\n"
    }
   ],
   "source": [
    "!rm -rf __MACOSX\n",
    "# !unzip -q /home/aistudio/data/data23617/characterData.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的包\n",
    "\n",
    "import numpy as np\n",
    "import paddle as paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid import layers\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "from paddle.fluid.dygraph import Pool2D,Conv2D,BatchNorm,CosineDecay\n",
    "# from paddle.fluid.dygraph import FC\n",
    "from paddle.fluid.dygraph import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成车牌字符图像列表\n",
    "data_path = '/home/aistudio/data'\n",
    "character_folders = os.listdir(data_path)\n",
    "label = 0\n",
    "LABEL_temp = {}\n",
    "if(os.path.exists('./train_data.list')):\n",
    "    os.remove('./train_data.list')\n",
    "if(os.path.exists('./test_data.list')):\n",
    "    os.remove('./test_data.list')\n",
    "for character_folder in character_folders:\n",
    "    with open('./train_data.list', 'a') as f_train:\n",
    "        with open('./test_data.list', 'a') as f_test:\n",
    "            if character_folder == '.DS_Store' or character_folder == '.ipynb_checkpoints' or character_folder == 'data23617':\n",
    "                continue\n",
    "            # print(character_folder + \" \" + str(label))\n",
    "            LABEL_temp[str(label)] = character_folder #存储一下标签的对应关系\n",
    "            character_imgs = os.listdir(os.path.join(data_path, character_folder))\n",
    "            for i in range(len(character_imgs)):\n",
    "                if i%10 == 0: \n",
    "                    f_test.write(os.path.join(os.path.join(data_path, character_folder), character_imgs[i]) + \"\\t\" + str(label) + '\\n')\n",
    "                else:\n",
    "                    f_train.write(os.path.join(os.path.join(data_path, character_folder), character_imgs[i]) + \"\\t\" + str(label) + '\\n')\n",
    "    label = label + 1\n",
    "print('图像列表已生成',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(X, y):\n",
    "    '''\n",
    "        功能：图像增强，mixup\n",
    "        参数：\n",
    "            X：batch imgs\n",
    "            y: batch labels\n",
    "        超参：\n",
    "            beta: beta分布的alpha和beta参数，这个可以自己设置，并观察结果\n",
    "        引用：\n",
    "            mixup: Beyond Empirical Risk Minimization(https://arxiv.org/abs/1710.09412)\n",
    "    '''\n",
    "    mixup_alpha = 0.1\n",
    "    seed = np.random.beta(mixup_alpha, mixup_alpha)\n",
    "    index = np.arange(X.shape[0])\n",
    "    np.random.shuffle(index)\n",
    "    images_a, images_b = X, X[index]\n",
    "    labels_a, labels_b = y, y[index]\n",
    "    mixed_images = seed * images_a + (1 - seed) * images_b\n",
    "    return mixed_images, labels_a, labels_b, seed\n",
    "\n",
    "\n",
    "# 用上一步生成的图像列表定义车牌字符训练集和测试集的reader\n",
    "def data_mapper(sample):\n",
    "    img, label = sample\n",
    "    img = paddle.dataset.image.load_image(file=img, is_color=False)\n",
    "    img = img.flatten().astype('float32') / 255.0\n",
    "    return img, label\n",
    "def data_reader(data_list_path):\n",
    "    def reader():\n",
    "        with open(data_list_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                img, label = line.split('\\t')\n",
    "                yield img, int(label)\n",
    "    return paddle.reader.xmap_readers(data_mapper, reader, cpu_count(), 10240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于训练的数据提供器\n",
    "BATCH_SIZE = 128\n",
    "train_reader = paddle.batch(reader=paddle.reader.shuffle(reader=data_reader('./train_data.list'), buf_size=51200), batch_size=BATCH_SIZE)\n",
    "# 用于测试的数据提供器\n",
    "test_reader = paddle.batch(reader=data_reader('./test_data.list'), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(train_reader())\n",
    "data[0][0].shape, data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义网络\n",
    "\n",
    "# out_chs = [6, 16, 256]\n",
    "# out_chs = [16, 32, 256]\n",
    "# out_chs = [16, 32, 512]\n",
    "out_chs = [32, 64, 256]\n",
    "# out_chs = [32, 64, 1024]\n",
    "class MyLeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, *, channels, fig_size, num_class):\n",
    "        super(MyLeNet,self).__init__()\n",
    "        self.hidden1_1 = Conv2D(channels, out_chs[0], 5, padding=2)\n",
    "        self.bn1 = BatchNorm(out_chs[0], act='relu')\n",
    "        self.hidden1_2 = Pool2D(2, 'avg', 2)\n",
    "        self.hidden2_1 = Conv2D(out_chs[0], out_chs[1], 3, padding=1)\n",
    "        self.bn2 = BatchNorm(out_chs[1], act='relu')\n",
    "        self.hidden2_2 = Pool2D(2, 'avg', 2)\n",
    "        self.hidden3 = Conv2D(out_chs[1], out_chs[2] ,1) # 第三个卷积层用 1*1 卷积， 相当于全链接层，但是参数要少的多\n",
    "        self.bn3 = BatchNorm(out_chs[2], act='relu')\n",
    "        self.global_avg_pool = Pool2D(pool_type='avg', global_pooling=True)\n",
    "        self.hidden4 = Linear(out_chs[2], num_class, act='softmax')\n",
    "    def forward(self,input):\n",
    "        x = self.bn1(self.hidden1_1(input))\n",
    "        x = self.hidden1_2(x)\n",
    "\n",
    "        x = self.bn2(self.hidden2_1(x))\n",
    "        x = self.hidden2_2(x)\n",
    "\n",
    "        x = self.bn3(self.hidden3(x))\n",
    "        x = self.global_avg_pool(x)\n",
    "\n",
    "        x = fluid.layers.flatten(x)\n",
    "        y = self.hidden4(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 200\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "with fluid.dygraph.guard():\n",
    "    model=MyLeNet(channels=1, fig_size=20, num_class=65) #模型实例化\n",
    "    model.train() #训练模式\n",
    "    lr = 0.1 * (BATCH_SIZE / 256)\n",
    "    opt=fluid.optimizer.SGDOptimizer(learning_rate=CosineDecay(lr, EPOCH, EPOCH), parameter_list=model.parameters())#优化器选用SGD随机梯度下降，学习率为0.001.\n",
    "    epochs_num= EPOCH #迭代次数为20\n",
    "    \n",
    "    for pass_num in range(epochs_num):\n",
    "        n, train_loss, train_acc = 0, 0, 0\n",
    "        for batch_id,data in enumerate(train_reader()):\n",
    "            images=np.array([x[0].reshape(1,20,20) for x in data],np.float32)\n",
    "            labels = np.array([x[1] for x in data]).astype('int64')\n",
    "            # images, labels_a, labels_b, seed = mixup(images, labels)\n",
    "            labels = labels[:, np.newaxis]\n",
    "            image=fluid.dygraph.to_variable(images)\n",
    "            label=fluid.dygraph.to_variable(labels)\n",
    "            \n",
    "            predict=model(image)#预测\n",
    "            \n",
    "            loss=fluid.layers.cross_entropy(predict,label)\n",
    "            # loss = seed * fluid.layers.cross_entropy(predict, fluid.dygraph.to_variable(labels_a)) + (1 - seed) * fluid.layers.cross_entropy(predict, fluid.dygraph.to_variable(labels_b))\n",
    "            avg_loss=fluid.layers.mean(loss)#获取loss值\n",
    "            \n",
    "            acc=fluid.layers.accuracy(predict,label)#计算精度\n",
    "            # acc = seed * fluid.layers.accuracy(predict, layers.unsqueeze(fluid.dygraph.to_variable(labels_a), axes=[1])) + (1 - seed) * fluid.layers.accuracy(predict, layers.unsqueeze(fluid.dygraph.to_variable(labels_b),axes=[1]))\n",
    "            \n",
    "            # if batch_id!=0 and batch_id%50==0:\n",
    "            #     print(\"train_pass:{},batch_id:{},train_loss:{},train_acc:{}\".format(pass_num,batch_id,avg_loss.numpy(),acc.numpy()))\n",
    "            n += 1\n",
    "            train_loss += avg_loss.numpy()\n",
    "            train_acc += acc.numpy()\n",
    "            avg_loss.backward()\n",
    "            opt.minimize(avg_loss)\n",
    "            model.clear_gradients() \n",
    "        print(\"train_pass:{},train_loss:{},train_acc:{}\".format(pass_num,train_loss / n,train_acc / n))\n",
    "        train_losses.append(train_loss / n)\n",
    "        train_accs.append(train_acc / n)                   \n",
    "        fluid.save_dygraph(model.state_dict(),'MyLeNet')#保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(train_losses)\n",
    "plt.title('loss')\n",
    "plt.subplot(122)\n",
    "plt.plot(train_accs)\n",
    "plt.title('acc')\n",
    "plt.savefig('32_64_256.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型校验\n",
    "with fluid.dygraph.guard():\n",
    "    accs = []\n",
    "    model=MyLeNet(channels=1, fig_size=20, num_class=65)#模型实例化\n",
    "    model_dict,_=fluid.load_dygraph('MyLeNet')\n",
    "    model.load_dict(model_dict)#加载模型参数\n",
    "    model.eval()#评估模式\n",
    "    for batch_id,data in enumerate(test_reader()):#测试集\n",
    "        images=np.array([x[0].reshape(1,20,20) for x in data],np.float32)\n",
    "        labels = np.array([x[1] for x in data]).astype('int64')\n",
    "        labels = labels[:, np.newaxis]\n",
    "            \n",
    "        image=fluid.dygraph.to_variable(images)\n",
    "        label=fluid.dygraph.to_variable(labels)\n",
    "            \n",
    "        predict=model(image)#预测\n",
    "        acc=fluid.layers.accuracy(predict,label)\n",
    "        accs.append(acc.numpy()[0])\n",
    "        avg_acc = np.mean(accs)\n",
    "    print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对车牌图片进行处理，分割出车牌中的每一个字符并保存\n",
    "license_plate = cv2.imread('./车牌.png')\n",
    "gray_plate = cv2.cvtColor(license_plate, cv2.COLOR_RGB2GRAY)\n",
    "ret, binary_plate = cv2.threshold(gray_plate, 175, 255, cv2.THRESH_BINARY)\n",
    "result = []\n",
    "for col in range(binary_plate.shape[1]):\n",
    "    result.append(0)\n",
    "    for row in range(binary_plate.shape[0]):\n",
    "        result[col] = result[col] + binary_plate[row][col]/255\n",
    "character_dict = {}\n",
    "num = 0\n",
    "i = 0\n",
    "while i < len(result):\n",
    "    if result[i] == 0:\n",
    "        i += 1\n",
    "    else:\n",
    "        index = i + 1\n",
    "        while result[index] != 0:\n",
    "            index += 1\n",
    "        character_dict[num] = [i, index-1]\n",
    "        num += 1\n",
    "        i = index\n",
    "\n",
    "for i in range(8):\n",
    "    if i==2:\n",
    "        continue\n",
    "    padding = (170 - (character_dict[i][1] - character_dict[i][0])) / 2\n",
    "    ndarray = np.pad(binary_plate[:,character_dict[i][0]:character_dict[i][1]], ((0,0), (int(padding), int(padding))), 'constant', constant_values=(0,0))\n",
    "    ndarray = cv2.resize(ndarray, (20,20))\n",
    "    cv2.imwrite('./' + str(i) + '.png', ndarray)\n",
    "    \n",
    "def load_image(path):\n",
    "    img = paddle.dataset.image.load_image(file=path, is_color=False)\n",
    "    img = img.astype('float32')\n",
    "    img = img[np.newaxis, ] / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将标签进行转换\n",
    "print('Label:',LABEL_temp)\n",
    "match = {'A':'A','B':'B','C':'C','D':'D','E':'E','F':'F','G':'G','H':'H','I':'I','J':'J','K':'K','L':'L','M':'M','N':'N',\n",
    "        'O':'O','P':'P','Q':'Q','R':'R','S':'S','T':'T','U':'U','V':'V','W':'W','X':'X','Y':'Y','Z':'Z',\n",
    "        'yun':'云','cuan':'川','hei':'黑','zhe':'浙','ning':'宁','jin':'津','gan':'赣','hu':'沪','liao':'辽','jl':'吉','qing':'青','zang':'藏',\n",
    "        'e1':'鄂','meng':'蒙','gan1':'甘','qiong':'琼','shan':'陕','min':'闽','su':'苏','xin':'新','wan':'皖','jing':'京','xiang':'湘','gui':'贵',\n",
    "        'yu1':'渝','yu':'豫','ji':'冀','yue':'粤','gui1':'桂','sx':'晋','lu':'鲁',\n",
    "        '0':'0','1':'1','2':'2','3':'3','4':'4','5':'5','6':'6','7':'7','8':'8','9':'9'}\n",
    "L = 0\n",
    "LABEL ={}\n",
    "\n",
    "for V in LABEL_temp.values():\n",
    "    LABEL[str(L)] = match[V]\n",
    "    L += 1\n",
    "print(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建预测动态图过程\n",
    "with fluid.dygraph.guard():\n",
    "    model=MyLeNet(channels=1, fig_size=20, num_class=65)#模型实例化\n",
    "    model_dict,_=fluid.load_dygraph('MyLeNet')\n",
    "    model.load_dict(model_dict)#加载模型参数\n",
    "    model.eval()#评估模式\n",
    "    lab=[]\n",
    "    for i in range(8):\n",
    "        if i==2:\n",
    "            continue\n",
    "        infer_imgs = []\n",
    "        infer_imgs.append(load_image('./' + str(i) + '.png'))\n",
    "        infer_imgs = np.array(infer_imgs)\n",
    "        infer_imgs = fluid.dygraph.to_variable(infer_imgs)\n",
    "        result=model(infer_imgs)\n",
    "        lab.append(np.argmax(result.numpy()))\n",
    "# print(lab)\n",
    "\n",
    "\n",
    "display(Image.open('./车牌.png'))\n",
    "print('\\n车牌识别结果为：',end='')\n",
    "for i in range(len(lab)):\n",
    "    print(LABEL[str(lab[i])],end='')"
   ]
  }
 ]
}